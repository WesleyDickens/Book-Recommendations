{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6e35199",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "cleaned_df = pd.read_csv('cleaned_df.csv')\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35bc1b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "import torch\n",
    "\n",
    "def load_sparse_matrix_to_tensor(path):\n",
    "    # Load the sparse matrix from disk\n",
    "    sparse_matrix = sp.load_npz(path)\n",
    "    \n",
    "    # Convert the sparse matrix to a dense NumPy array\n",
    "    dense_array = sparse_matrix.toarray()\n",
    "    \n",
    "    # Convert the dense NumPy array to a PyTorch tensor\n",
    "    tensor = torch.tensor(dense_array, dtype=torch.float)\n",
    "    \n",
    "    return tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0d81277",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CollabFiltModel(nn.Module):\n",
    "    def __init__(self, num_users, num_items, emb_size=100):\n",
    "        super().__init__()\n",
    "        self.user_emb = nn.Embedding(num_users, emb_size)\n",
    "        self.item_emb = nn.Embedding(num_items, emb_size)\n",
    "    \n",
    "    def forward(self, user, item):\n",
    "        user_emb = self.user_emb(user)\n",
    "        item_emb = self.item_emb(item)\n",
    "        return (user_emb * item_emb).sum(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d18ead41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model (make sure it has the same architecture)\n",
    "loaded_model = CollabFiltModel(num_users=cleaned_df['User_id'].nunique(),\n",
    "                               num_items=cleaned_df['Title'].nunique()).to(device)\n",
    "\n",
    "# Load the model state dictionary\n",
    "loaded_model.load_state_dict(torch.load('collab_filt_model_state_dict.pth'))\n",
    "\n",
    "# Ensure to switch the model to evaluation mode\n",
    "loaded_model.eval()\n",
    "\n",
    "# Load the encoders\n",
    "user_encoder = joblib.load('user_encoder.joblib')\n",
    "item_encoder = joblib.load('item_encoder.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5baa7128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please choose a genre from the following list:\n",
      "1. ['Biography & Autobiography']\n",
      "2. ['Religion']\n",
      "3. ['Fiction']\n",
      "4. ['Social Science']\n",
      "5. ['Juvenile Nonfiction']\n",
      "6. ['History']\n",
      "7. ['Political Science']\n",
      "8. ['Health & Fitness']\n",
      "9. ['Cooking']\n",
      "10. ['Philosophy']\n",
      "11. ['Sports & Recreation']\n",
      "12. ['Body, Mind & Spirit']\n",
      "13. ['Juvenile Fiction']\n",
      "14. ['Family & Relationships']\n",
      "15. ['Science']\n",
      "16. ['Business & Economics']\n",
      "17. ['Computers']\n",
      "18. ['Self-Help']\n",
      "19. ['Young Adult Fiction']\n",
      "Enter the number corresponding to your choice: 3\n"
     ]
    }
   ],
   "source": [
    "loaded_model.eval()\n",
    "loaded_model.to('cpu') ## Faster\n",
    "\n",
    "# Extract item embeddings\n",
    "item_embeddings = loaded_model.item_emb.weight.data.cpu().numpy()\n",
    "\n",
    "# Filter genres to only include books with more than 20,000 examples\n",
    "filtered_df = cleaned_df[cleaned_df['categories'].isin(cleaned_df['categories'].value_counts()[cleaned_df['categories'].value_counts() > 20000].index)]\n",
    "\n",
    "unique_genres = filtered_df['categories'].unique()\n",
    "\n",
    "# Display the genres to the user\n",
    "print(\"Please choose a genre from the following list:\")\n",
    "for i, genre in enumerate(unique_genres, 1):\n",
    "    print(f\"{i}. {genre}\")\n",
    "\n",
    "choice = int(input(\"Enter the number corresponding to your choice: \")) - 1  # Subtract 1 to match the list index\n",
    "\n",
    "genre_choice = unique_genres[choice]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291ae637",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = cleaned_df[cleaned_df['categories'] == genre_choice][['Title', 'authors']].sample(5)\n",
    "\n",
    "sample_titles = sample_data['Title'].to_numpy()\n",
    "sample_authors = sample_data['authors'].to_numpy()\n",
    "\n",
    "decoded_titles = item_encoder.inverse_transform(sample_titles)\n",
    "\n",
    "user_ratings = {}\n",
    "print('Rate these books 1-5')\n",
    "for title, author in zip(decoded_titles, sample_authors):\n",
    "    score = input(f'{title} by {author}: ')\n",
    "    \n",
    "    encoded_value = item_encoder.transform([title])[0]\n",
    "    \n",
    "    user_ratings[encoded_value] = float(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df15d959",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "import numpy as np\n",
    "\n",
    "# Prepare the data for ridge regression\n",
    "rated_item_indices = list(user_ratings.keys())\n",
    "X = item_embeddings[rated_item_indices]\n",
    "y = np.array(list(user_ratings.values()))\n",
    "\n",
    "# Fit the ridge regression model\n",
    "ridge_model = Ridge(alpha=1.0)\n",
    "ridge_model.fit(X, y)\n",
    "\n",
    "# The user's \"embedding\" is approximated by the coefficients\n",
    "user_preferences = ridge_model.coef_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95162d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Rand McNally 2007 The Road Atlas & Travel Guide: U.S. / Canada / Mexico (Rand Mcnally Road Atlas and Festival Guide)'\n",
      " \"Pournelle's PC Communications Bible: The Ultimate Guide to Productivity With a Modem\"\n",
      " 'French Army 1870-71 Franco-Prussian War: 2 Republican Troops (Men-At-Arms Series, 237)'\n",
      " 'Enchanted Liguria: A Celebration of the Culture, Lifestyle and Food of the Italian Riviera'\n",
      " 'The Wedding Cake in the Middle of the Road: 23 Variations on a Theme']\n"
     ]
    }
   ],
   "source": [
    "# Predict ratings for all items\n",
    "predicted_ratings = np.dot(item_embeddings, user_preferences)\n",
    "\n",
    "# Rank items by predicted rating, excluding already rated items\n",
    "recommended_indices = np.argsort(-predicted_ratings)\n",
    "top_recommendations = [index for index in recommended_indices if index not in rated_item_indices][:5]\n",
    "\n",
    "# Decode the top recommended item indices to original IDs\n",
    "top_recommended_item_ids = item_encoder.inverse_transform(top_recommendations)\n",
    "\n",
    "print(top_recommended_item_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fcbe87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
